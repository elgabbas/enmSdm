% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/trainNs.r
\name{trainNs}
\alias{trainNs}
\title{Calibrate a natural splines model}
\usage{
trainNs(data, resp = names(data)[1], preds = names(data)[2:ncol(data)],
  family = "binomial", df = NULL, construct = TRUE, select = TRUE,
  presPerTermInitial = 10, presPerTermFinal = 20, initialTerms = 8,
  w = TRUE, out = "model", verbose = FALSE, ...)
}
\arguments{
\item{data}{Data frame.  Must contain fields with same names as in \code{preds} object.}

\item{resp}{Character or integer. Name or column index of response variable. Default is to use the first column in \code{data}.}

\item{preds}{Character list or integer list. Names of columns or column indices of predictors. Default is to use the second and subsequent columns in \code{data}.}

\item{family}{Name of family for data error structure (see \code{\link[stats]{family}}).}

\item{df}{Integer > 0 OR \code{NULL}. Sets flexibility of model fit. See documentation for \code{ns()}.}

\item{construct}{Logical. If TRUE then construct model by computing AICc for all univariate and bivariate models. Then add terms up to maximum set by \code{presPerTermInitial} and \code{initialTerms}.}

\item{select}{Logical. If TRUE then calculate AICc for all possible subsets of models and return the model with the lowest AICc of these. This step if performed \emph{after} model construction (if any).}

\item{presPerTermInitial}{Positive integer. Minimum number of presences needed per model term for a term to be included in the model construction stage. Used only is \code{construct} is TRUE.}

\item{presPerTermFinal}{Positive integer. Minimum number of presence sites per term in initial starting model; used only if \code{select} is TRUE.}

\item{initialTerms}{Positive integer. Maximum number of terms to be used in an initial model. Used only if \code{construct} is TRUE. The maximum that can be handled by \code{\link[MuMIn]{dredge }}is 31, so if this number is >31 and \code{select} is \code{TRUE} then it is forced to 31 with a warning. Note that the number of coefficients for factors is not calculated correctly, so if the predictors contain factors then this number might have to be reduced even more.}

\item{w}{Either logical in which case \code{TRUE} causes the total weight of presences to equal the total weight of absences (if \code{family='binomial'}) OR a numeric list of weights, one per row in \code{data} OR the name of the column in \code{data} that contains site weights. The default is to assign a weight of 1 to each datum.}

\item{out}{Character. Indicates type of value returned. If \code{model} (default) then returns an object of class \code{gam}. If \code{tuning} then just return the AICc table for each kind of model term used in model construction. If both then return a 2-item list with the best model and the AICc table.}

\item{verbose}{Logical. If TRUE then display intermediate results on the display device.}

\item{...}{Arguments to send to \code{gam()} or \code{dredge()}.}
}
\value{
If \code{out = 'model'} this function returns an object of class \code{gam}. If \code{out = 'tuning'} this function returns a data frame with tuning parameters and AICc for each model tried. If \code{out = c('model', 'tuning'} then it returns a list object with the \code{gam} object and the data frame.
}
\description{
This function constructs a natural-spline model piece-by-piece by first calculating AICc for all models with univariate and bivariate (interaction) terms. It then creates a "full" model with the highest-ranked uni/bivariate terms then implements an all-subsets model selection routine.
}
\examples{
\donttest{
set.seed(123)
x <- matrix(rnorm(n = 6*100), ncol = 6)
# true variables will be #1, #2, #5, and #6, plus
# the squares of #1 and #6, plus
# interaction between #1 and #6
# the cube of #5
imp <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x1_pow2', 'x6_pow2', 'x1_by_x6', 'x5_pow3')
betas <- c(5, 2, 0, 0, 1, -1, 8, 1, 2, -4)
names(betas) <- imp
y <- 0.5 + x \%*\% betas[1:6] + betas[7] * x[ , 1] +
betas[8] * x[ , 6] + betas[9] * x[ , 1] * x[ , 6] + betas[10] * x[ , 5]^3
y <- as.integer(y > 0)
x <- cbind(y, x)
x <- as.data.frame(x)
names(x) <- c('y', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6')
model <- trainNs(x, out=c('model', 'tuning'), verbose=TRUE)
model$tuning
summary(model$model)
}
}
\seealso{
\code{\link[splines]{ns}}, \code{\link[mgcv]{gam}}, \code{\link{trainGam}}
}
